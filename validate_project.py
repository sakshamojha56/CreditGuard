#!/usr/bin/env python3
"""
Project validation script for Credit Card Default Prediction.

This script validates that all components are properly set up and working.
"""

import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path

def validate_project_structure():
    """Validate that all required directories and files exist."""
    print("ğŸ” Validating project structure...")
    
    required_dirs = ['data', 'notebooks', 'src', 'models', 'results']
    required_files = [
        'README.md',
        'requirements.txt', 
        'PROJECT_SUMMARY.md',
        '__init__.py',
        'src/__init__.py',
        'src/data_preprocessing.py',
        'src/feature_engineering.py', 
        'src/model_training.py',
        'src/evaluation.py'
    ]
    
    missing_dirs = []
    missing_files = []
    
    # Check directories
    for dir_name in required_dirs:
        if not os.path.exists(dir_name):
            missing_dirs.append(dir_name)
    
    # Check files
    for file_name in required_files:
        if not os.path.exists(file_name):
            missing_files.append(file_name)
    
    if missing_dirs:
        print(f"âŒ Missing directories: {missing_dirs}")
        return False
    
    if missing_files:
        print(f"âŒ Missing files: {missing_files}")
        return False
    
    print("âœ… Project structure validated successfully!")
    return True

def validate_data():
    """Validate that the training data exists and is readable."""
    print("ğŸ“Š Validating data...")
    
    data_file = 'data/train.csv'
    if not os.path.exists(data_file):
        print(f"âŒ Training data not found: {data_file}")
        return False
    
    try:
        df = pd.read_csv(data_file)
        print(f"âœ… Training data loaded: {df.shape[0]:,} rows, {df.shape[1]} columns")
        
        # Check for required columns
        required_cols = ['Customer_ID', 'next_month_default', 'LIMIT_BAL', 'age']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            print(f"âŒ Missing required columns: {missing_cols}")
            return False
        
        # Check target distribution
        target_dist = df['next_month_default'].value_counts(normalize=True)
        print(f"ğŸ“ˆ Target distribution: {target_dist.to_dict()}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error loading data: {str(e)}")
        return False

def validate_modules():
    """Validate that all Python modules can be imported."""
    print("ğŸ Validating Python modules...")
    
    try:
        sys.path.append('src')
        
        from data_preprocessing import DataPreprocessor
        from feature_engineering import FeatureEngineer
        from model_training import ModelTrainer
        from evaluation import ModelEvaluator
        
        print("âœ… All modules imported successfully!")
        return True
        
    except ImportError as e:
        print(f"âŒ Import error: {str(e)}")
        return False
    except Exception as e:
        print(f"âŒ Unexpected error: {str(e)}")
        return False

def validate_notebooks():
    """Validate that all notebooks exist."""
    print("ğŸ““ Validating notebooks...")
    
    notebook_dir = 'notebooks'
    expected_notebooks = [
        '01_data_exploration.ipynb',
        '02_feature_engineering.ipynb', 
        '03_model_development.ipynb',
        '04_model_evaluation.ipynb'
    ]
    
    missing_notebooks = []
    for notebook in expected_notebooks:
        notebook_path = os.path.join(notebook_dir, notebook)
        if not os.path.exists(notebook_path):
            missing_notebooks.append(notebook)
    
    if missing_notebooks:
        print(f"âŒ Missing notebooks: {missing_notebooks}")
        return False
    
    print("âœ… All notebooks found!")
    return True

def run_quick_test():
    """Run a quick end-to-end test of the main pipeline."""
    print("ğŸ§ª Running quick pipeline test...")
    
    try:
        sys.path.append('src')
        from data_preprocessing import load_and_preprocess_data
        from feature_engineering import engineer_features_for_dataset
        
        # Load and preprocess a small sample
        print("  Loading data...")
        train_data, _, metadata = load_and_preprocess_data("data/train.csv")
        
        # Sample for quick test
        sample_data = train_data.sample(n=min(1000, len(train_data)), random_state=42)
        
        print("  Engineering features...")
        engineered_data, selected_features, descriptions = engineer_features_for_dataset(sample_data)
        
        print(f"  âœ… Pipeline test completed!")
        print(f"  Original features: {sample_data.shape[1]}")
        print(f"  Engineered features: {engineered_data.shape[1]}")
        print(f"  Selected features: {len(selected_features)}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Pipeline test failed: {str(e)}")
        return False

def print_project_summary():
    """Print a summary of the project."""
    print("\n" + "="*60)
    print("ğŸ“‹ CREDIT CARD DEFAULT PREDICTION PROJECT")
    print("="*60)
    print("ğŸ¯ Objective: Predict credit card default risk")
    print("ğŸ“Š Dataset: 25,249 customers with 26 features")
    print("ğŸ”§ Methods: Feature engineering + ML classification")
    print("ğŸ“ˆ Target: F2 Score >0.75 (emphasizes recall)")
    print("ğŸ—ï¸ Architecture: Modular Python codebase")
    print("ğŸ““ Documentation: 4 comprehensive notebooks")
    print("ğŸš€ Status: Production-ready implementation")
    print("="*60)
    
    print("\nğŸ“ Project Structure:")
    print("â”œâ”€â”€ data/                  # Training dataset")
    print("â”œâ”€â”€ notebooks/             # Analysis & modeling")
    print("â”œâ”€â”€ src/                   # Source code modules")
    print("â”œâ”€â”€ models/                # Trained model artifacts")
    print("â”œâ”€â”€ results/               # Predictions & reports")
    print("â”œâ”€â”€ README.md             # Project documentation")
    print("â”œâ”€â”€ PROJECT_SUMMARY.md    # Comprehensive summary")
    print("â””â”€â”€ requirements.txt      # Dependencies")
    
    print("\nğŸ¯ Next Steps:")
    print("1. Run notebooks in order (01 â†’ 02 â†’ 03 â†’ 04)")
    print("2. Explore data patterns and feature engineering")
    print("3. Train and compare multiple models")
    print("4. Evaluate performance and explainability")
    print("5. Deploy to production environment")
    print("="*60)

def main():
    """Main validation function."""
    print("ğŸ” CREDIT CARD DEFAULT PREDICTION - PROJECT VALIDATION")
    print("="*60)
    
    all_valid = True
    
    # Run all validation checks
    all_valid &= validate_project_structure()
    all_valid &= validate_data()
    all_valid &= validate_modules()
    all_valid &= validate_notebooks()
    all_valid &= run_quick_test()
    
    print("\n" + "="*60)
    if all_valid:
        print("âœ… ALL VALIDATIONS PASSED!")
        print("ğŸš€ Project is ready for use!")
    else:
        print("âŒ SOME VALIDATIONS FAILED!")
        print("âš ï¸ Please fix issues before proceeding.")
    
    print_project_summary()

if __name__ == "__main__":
    main()
